{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb1a7b05-c78b-4f75-a7c1-f1d23cf970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, least_squares\n",
    "import csv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "305b18f5-c52c-4064-844f-284fc0eadee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDialect(csv.Dialect):\n",
    "    delimiter = ' '\n",
    "    skipinitialspace = True\n",
    "    quoting = csv.QUOTE_NONE\n",
    "    lineterminator = '\\n'\n",
    "    quotechar = '\"'  # Use double quote as quotechar\n",
    "\n",
    "csv.register_dialect('custom', CustomDialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "945f9c8c-2f93-4277-a339-384faa47bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### READ THE IMU FILE IN ASCII seperated columns ####\n",
    "\n",
    "def read_imu_data(file_path):\n",
    "    imu_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, dialect='custom')\n",
    "        next(csv_reader)  # Skip the header line\n",
    "        for row_num, row in enumerate(csv_reader, start=2):  # Start counting from line 2\n",
    "            try:\n",
    "                row = [field for field in row if field]  # Remove empty fields\n",
    "                if len(row) != 7:\n",
    "                    print(f\"Warning: Line {row_num} has {len(row)} values instead of 7\")\n",
    "                    continue\n",
    "                # Convert all values to float and store in a flat list\n",
    "                data = [float(val) for val in row]\n",
    "                imu_data.append(data)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error on line {row_num}: {e}\")\n",
    "                print(f\"Problematic row: {row}\")\n",
    "            except IndexError as e:\n",
    "                print(f\"Error on line {row_num}: Not enough values in the row\")\n",
    "                print(f\"Problematic row: {row}\")\n",
    "    \n",
    "    return np.array(imu_data)\n",
    "    \n",
    "#### TIMESTAMPED IMAGES #### NAMING FORMAT - {SERIAL NUMBER}_{FALLING EDGE OF TRIGGER SIGNAL}_{RISING EDGE OF TRIGGER SIGNAL}.jpg ####\n",
    "def parse_image_filename(filename):\n",
    "    # Extract the timing information from the image filename\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Filename {filename} does not match expected format.\")\n",
    "    \n",
    "    falling_edge = float(parts[1])\n",
    "    rising_edge = float(parts[2].split('.')[0])  # Remove the file extension\n",
    "    \n",
    "    return falling_edge, rising_edge\n",
    "\n",
    "#### FIND THE CLOSEST IMAGE AND IMU TIMESTAMP TO SYNC ####\n",
    "def find_closest_imu_data(imu_data, timestamp):\n",
    "    # Find the IMU data that is closest to the given timestamp\n",
    "    imu_times = imu_data[:, 0]\n",
    "    index = np.argmin(np.abs(imu_times - timestamp))\n",
    "    return imu_data[index]\n",
    "        \n",
    "#### USE OPENCV ORB KEYPOINT IDENTIFIER & DESCRIPTOR. SCALE FACTOR >1, higher value bad reso less time, near 1 good reso more time #### \n",
    "def orb_detector_descriptor(image, nfeatures=5000, scale_factor=1.2, nlevels=8):\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures, scaleFactor=scale_factor, nlevels=nlevels)\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "#### IDENTIFY IF THE CURRENT FRAME IS A KEYFRAME ####\n",
    "def is_keyframe(current_kp, last_keyframe_kp, min_matches=50):\n",
    "    if len(last_keyframe_kp) == 0:\n",
    "        return True\n",
    "    return len(current_kp) >= min_matches\n",
    "\n",
    "\n",
    "#### REFINE THE ESSENTIAL MATRIX USING THE KEYPOINTS IN 2 FRAMES BY REDUCING THE ERROR ####\n",
    "def refine_E(E, p1, p2, K):\n",
    "    def objective(E_vec):\n",
    "        E_mat = E_vec.reshape(3, 3)\n",
    "        p1_norm = cv2.undistortPoints(p1.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
    "        p2_norm = cv2.undistortPoints(p2.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
    "        error = 0\n",
    "        for i in range(len(p1_norm)):\n",
    "            p1_homogeneous = np.append(p1_norm[i], 1)\n",
    "            p2_homogeneous = np.append(p2_norm[i], 1)\n",
    "            error += np.abs(np.dot(p2_homogeneous, np.dot(E_mat, p1_homogeneous)))\n",
    "        return error\n",
    "\n",
    "    result = minimize(objective, E.flatten(), method='Nelder-Mead')\n",
    "    return result.x.reshape(3, 3)\n",
    "\n",
    "#### MOTION BUNDLE ADJUSTMENT ####\n",
    "def motion_only_bundle_adjustment(R, t, points_3d, points_2d, K):\n",
    "    def project(points_3d, rvec, tvec, K):\n",
    "        points_proj, _ = cv2.projectPoints(points_3d, rvec, tvec, K, None)\n",
    "        return points_proj.reshape(-1, 2)\n",
    "\n",
    "    def objective(params):\n",
    "        rvec, tvec = params[:3], params[3:]\n",
    "        points_proj = project(points_3d, rvec, tvec, K)\n",
    "        errors = points_proj - points_2d\n",
    "        return errors.ravel()\n",
    "\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    params = np.hstack((rvec.ravel(), t.ravel()))\n",
    "    \n",
    "    result = least_squares(objective, params, loss='soft_l1', f_scale=1.0, verbose=0)\n",
    "\n",
    "    R_opt, _ = cv2.Rodrigues(result.x[:3])\n",
    "    t_opt = result.x[3:].reshape(3, 1)\n",
    "\n",
    "    return R_opt, t_opt\n",
    "\n",
    "\n",
    "#### FEATURE DISTANCE MATCH TO SEE REPITION AND DECLARE A LOOP CLOSURE ####\n",
    "def detect_loop_closures(trajectory, descriptors, distance_threshold=5.0, similarity_threshold=0.7):\n",
    "    loop_closures = []\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "    nn.fit(trajectory)\n",
    "    \n",
    "    for i in range(len(trajectory)):\n",
    "        distances, indices = nn.kneighbors([trajectory[i]])\n",
    "        for j, distance in zip(indices[0], distances[0]):\n",
    "            if j > i + 10 and distance < distance_threshold:  # Avoid consecutive frames\n",
    "                matches = flann.knnMatch(descriptors[i], descriptors[j], k=2)\n",
    "                good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "                if len(good_matches) / len(matches) > similarity_threshold:\n",
    "                    loop_closures.append((i, j))\n",
    "    \n",
    "    return loop_closures\n",
    "\n",
    "### CERATES POSE GRAPH FOR OPTIMIZATION ####\n",
    "def create_pose_graph(trajectory, loop_closures):\n",
    "    g = nx.Graph()\n",
    "    for i in range(len(trajectory) - 1):\n",
    "        g.add_edge(i, i+1, weight=1)\n",
    "    \n",
    "    for i, j in loop_closures:\n",
    "        g.add_edge(i, j, weight=0.1)  # Lower weight for loop closures\n",
    "    \n",
    "    return g\n",
    "\n",
    "#### POSE GRAPH OPTIMIZATION ####\n",
    "def optimize_pose_graph(trajectory, pose_graph):\n",
    "    n = len(trajectory)\n",
    "    \n",
    "    def objective(x):\n",
    "        residuals = []\n",
    "        for u, v, data in pose_graph.edges(data=True):\n",
    "            p1 = x[u*3:u*3+3]\n",
    "            p2 = x[v*3:v*3+3]\n",
    "            weight = data['weight']\n",
    "            residuals.append((p2 - p1) * weight)\n",
    "        return np.concatenate(residuals)\n",
    "    \n",
    "    x0 = trajectory.flatten()\n",
    "    res = least_squares(objective, x0)\n",
    "    return res.x.reshape(-1, 3)\n",
    "\n",
    "\n",
    "#### CLAHE IMPLEMENTATION TO IMPROVE CONTRAST IN IMAGE FOR BETTER KEYPOINT IDENTIFICATION ####\n",
    "def enhance_contrast(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150716a-f575-4d6e-89c3-9d0d99fac171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the folder containing images:  E:\\Shwetabh\\support cases\\temp\\peteorbovich_raw-data-point-cloud_2024-08-28_2113\\TRIDAR-5CD65E-2024-08-27-13-32-18\\camera\n",
      "Enter the path to the IMU data file:  E:\\Shwetabh\\support cases\\temp\\peteorbovich_raw-data-point-cloud_2024-08-28_2113\\TRIDAR-5CD65E-2024-08-27-13-32-18\\ins\\imu.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough good matches for image 5: 8\n",
      "Not enough good matches for image 40: 8\n",
      "Not enough good matches for image 41: 1\n",
      "Not enough good matches for image 42: 5\n",
      "Not enough good matches for image 46: 4\n",
      "Not enough good matches for image 47: 8\n",
      "Not enough good matches for image 48: 7\n",
      "Not enough good matches for image 49: 4\n",
      "Not enough good matches for image 50: 5\n",
      "Not enough good matches for image 51: 5\n",
      "Not enough good matches for image 52: 8\n",
      "Not enough good matches for image 54: 6\n",
      "Not enough good matches for image 56: 6\n",
      "Not enough good matches for image 57: 4\n",
      "Not enough good matches for image 58: 8\n",
      "Not enough good matches for image 59: 7\n",
      "Not enough good matches for image 60: 8\n",
      "Not enough good matches for image 61: 6\n",
      "Not enough good matches for image 62: 7\n",
      "Not enough good matches for image 63: 5\n",
      "Not enough good matches for image 64: 7\n",
      "Not enough good matches for image 66: 3\n",
      "Not enough good matches for image 67: 4\n",
      "Not enough good matches for image 68: 5\n",
      "Not enough good matches for image 69: 5\n",
      "Not enough good matches for image 70: 6\n",
      "Not enough good matches for image 74: 6\n",
      "Not enough good matches for image 80: 4\n",
      "Not enough good matches for image 81: 3\n",
      "Not enough good matches for image 82: 7\n",
      "Not enough good matches for image 83: 2\n",
      "Not enough good matches for image 93: 5\n",
      "Not enough good matches for image 122: 6\n",
      "Not enough good matches for image 123: 6\n"
     ]
    }
   ],
   "source": [
    "# Kalman Filter initialization\n",
    "# State vector [x, y, z, vx, vy, vz, roll, pitch, yaw]\n",
    "x_kalman = np.zeros(9)\n",
    "\n",
    "# State covariance matrix\n",
    "P_kalman = np.eye(9)\n",
    "\n",
    "# Process noise covariance matrix (Q)\n",
    "Q_kalman = np.eye(9) * 1e-4\n",
    "\n",
    "# Measurement noise covariance matrix (R)\n",
    "R_kalman = np.eye(6) * 0.1  # 6x6 to include roll, pitch, yaw\n",
    "\n",
    "# State transition matrix (F)\n",
    "dt = 5  # Time step, can be set based on your frame rate\n",
    "F_kalman = np.eye(9)\n",
    "F_kalman[0, 3] = F_kalman[1, 4] = F_kalman[2, 5] = dt  # Velocity affects position\n",
    "\n",
    "# Measurement matrix (H)\n",
    "H_kalman = np.zeros((6, 9))\n",
    "H_kalman[0, 0] = H_kalman[1, 1] = H_kalman[2, 2] = 1  # Measuring x, y, z\n",
    "H_kalman[3, 6] = H_kalman[4, 7] = H_kalman[5, 8] = 1  # Measuring roll, pitch, yaw\n",
    "\n",
    "# Main execution\n",
    "K = np.array([\n",
    "    [4085.11, 0, 3000],\n",
    "    [0, 4102.56, 2000],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "image_folder = input(\"Enter the path to the folder containing images: \")\n",
    "imu_file = input(\"Enter the path to the IMU data file: \")\n",
    "\n",
    "# Read IMU data\n",
    "imu_data = read_imu_data(imu_file)\n",
    "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "images = []\n",
    "gray_images = []\n",
    "keypoints = []\n",
    "descriptors = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    gray_img = enhance_contrast(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    images.append(img)\n",
    "    gray_images.append(gray_img)\n",
    "    \n",
    "    k, d = orb_detector_descriptor(gray_img)\n",
    "    keypoints.append(k)\n",
    "    descriptors.append(d)\n",
    "\n",
    "# FLANN matcher\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Calculate camera trajectory\n",
    "R_total = np.eye(3)\n",
    "t_total = np.zeros((3, 1))\n",
    "trajectory = [np.zeros(3)]  # Start at origin\n",
    "all_descriptors = [descriptors[0]]  # Store all descriptors for loop closure\n",
    "\n",
    "last_keyframe_kp = keypoints[0]\n",
    "last_keyframe_desc = descriptors[0]\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    try:\n",
    "        matches = flann.knnMatch(last_keyframe_desc, descriptors[i], k=2)\n",
    "        good_matches = []\n",
    "        for m in matches:\n",
    "            if len(m) == 2:\n",
    "                m, n = m\n",
    "                if m.distance < 0.7 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "    except Exception as e:\n",
    "        print(f\"Error matching features for image {i}: {str(e)}\")\n",
    "        continue  # Skip this iteration and move to the next image\n",
    "\n",
    "    if len(good_matches) > 8:  # 8-point algorithm requires at least 8 points\n",
    "        try:\n",
    "            src_pts = np.float32([last_keyframe_kp[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([keypoints[i][m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            E, mask = cv2.findEssentialMat(src_pts, dst_pts, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "            E_refined = refine_E(E, src_pts, dst_pts, K)\n",
    "            \n",
    "            _, R, t, mask = cv2.recoverPose(E_refined, src_pts, dst_pts, K)\n",
    "            R_total = R @ R_total\n",
    "            t_total += R_total @ t\n",
    "            \n",
    "            # Apply motion-only bundle adjustment\n",
    "            points_3d = cv2.triangulatePoints(np.hstack((np.eye(3), np.zeros((3, 1)))), np.hstack((R_total, t_total)), src_pts, dst_pts)\n",
    "            points_3d /= points_3d[3]  # Convert to homogeneous coordinates\n",
    "            points_2d = dst_pts.reshape(-1, 2)\n",
    "            R_opt, t_opt = motion_only_bundle_adjustment(R_total, t_total, points_3d[:3].T, points_2d, K)\n",
    "            R_total = R_opt\n",
    "            t_total = t_opt\n",
    "        \n",
    "        # Kalman filter prediction step\n",
    "            x_kalman[:3] += x_kalman[3:6] * dt  # Update position based on velocity\n",
    "            F_kalman[6:, 6:] = R_total  # Update rotation matrix\n",
    "            P_kalman = F_kalman @ P_kalman @ F_kalman.T + Q_kalman\n",
    "    \n",
    "            # Kalman filter correction step\n",
    "            z_kalman = np.hstack((t_total.ravel(), cv2.Rodrigues(R_total)[0].ravel()))  # Measurement vector\n",
    "            y_kalman = z_kalman - H_kalman @ x_kalman  # Measurement residual\n",
    "            S_kalman = H_kalman @ P_kalman @ H_kalman.T + R_kalman  # Residual covariance\n",
    "            K_kalman = P_kalman @ H_kalman.T @ np.linalg.inv(S_kalman)  # Kalman gain\n",
    "            x_kalman += K_kalman @ y_kalman\n",
    "            P_kalman = (np.eye(len(x_kalman)) - K_kalman @ H_kalman) @ P_kalman\n",
    "    \n",
    "            # Store the current position in the trajectory\n",
    "            trajectory.append(x_kalman[:3])\n",
    "            \n",
    "            # Update keyframe if the current frame is a keyframe\n",
    "            if is_keyframe(keypoints[i], last_keyframe_kp):\n",
    "                last_keyframe_kp = keypoints[i]\n",
    "                last_keyframe_desc = descriptors[i]\n",
    "                all_descriptors.append(descriptors[i])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {i}: {str(e)}\")\n",
    "            continue  # Skip this iteration and move to the next image\n",
    "    else:\n",
    "        print(f\"Not enough good matches for image {i}: {len(good_matches)}\")\n",
    "\n",
    "# Detect loop closures\n",
    "loop_closures = detect_loop_closures(np.array(trajectory), all_descriptors)\n",
    "pose_graph = create_pose_graph(np.array(trajectory), loop_closures)\n",
    "optimized_trajectory = optimize_pose_graph(np.array(trajectory), pose_graph)\n",
    "\n",
    "# Plot the results\n",
    "trajectory = np.array(trajectory)\n",
    "optimized_trajectory = np.array(optimized_trajectory)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1], label='Original Trajectory')\n",
    "plt.plot(optimized_trajectory[:, 0], optimized_trajectory[:, 1], label='Optimized Trajectory')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Camera Trajectory')\n",
    "plt.show()\n",
    "\n",
    "print(\"Pose estimation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93012b1c-0205-42e3-8100-32c3fc8c0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(pose_graph)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
