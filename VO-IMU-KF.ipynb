{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a7b05-c78b-4f75-a7c1-f1d23cf970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, least_squares\n",
    "import csv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f9c8c-2f93-4277-a339-384faa47bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### READ THE IMU FILE IN ASCII seperated columns ####\n",
    "def read_imu_data(file_path):\n",
    "    imu_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=' ')\n",
    "        next(csv_reader)  # Skip header\n",
    "        for row in csv_reader:\n",
    "            timestamp = float(row[0])\n",
    "            heading = float(row[1])\n",
    "            pitch = float(row[2])\n",
    "            roll = float(row[3])\n",
    "            imu_data.append([timestamp, heading, pitch, roll])\n",
    "    return np.array(imu_data)\n",
    "\n",
    "#### TIMESTAMPED IMAGES #### NAMING FORMAT - {SERIAL NUMBER}_{FALLING EDGE OF TRIGGER SIGNAL}_{RISING EDGE OF TRIGGER SIGNAL}.jpg ####\n",
    "def extract_timestamps_from_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    falling_edge = float(parts[1])\n",
    "    rising_edge = float(parts[2].split('.')[0])\n",
    "    return falling_edge, rising_edge\n",
    "\n",
    "#### FIND THE CLOSEST IMAGE AND IMU TIMESTAMP TO SYNC ####\n",
    "def find_closest_imu_data(imu_data, falling_edge, rising_edge):\n",
    "    closest_index = np.argmin(np.abs(imu_data[:, 0] - falling_edge))\n",
    "    if imu_data[closest_index][0] >= falling_edge and imu_data[closest_index][0] <= rising_edge:\n",
    "        return imu_data[closest_index]\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "#### USE OPENCV ORB KEYPOINT IDENTIFIER & DESCRIPTOR. SCALE FACTOR >1, higher value bad reso less time, near 1 good reso more time #### \n",
    "def orb_detector_descriptor(image, nfeatures=5000, scale_factor=1.2, nlevels=8):\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures, scaleFactor=scale_factor, nlevels=nlevels)\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "#### IDENTIFY IF THE CURRENT FRAME IS A KEYFRAME ####\n",
    "def is_keyframe(current_kp, last_keyframe_kp, min_matches=50):\n",
    "    if len(last_keyframe_kp) == 0:\n",
    "        return True\n",
    "    return len(current_kp) >= min_matches\n",
    "\n",
    "\n",
    "#### REFINE THE ESSENTIAL MATRIX USING THE KEYPOINTS IN 2 FRAMES BY REDUCING THE ERROR ####\n",
    "def refine_E(E, p1, p2, K):\n",
    "    def objective(E_vec):\n",
    "        E_mat = E_vec.reshape(3, 3)\n",
    "        p1_norm = cv2.undistortPoints(p1.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
    "        p2_norm = cv2.undistortPoints(p2.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
    "        error = 0\n",
    "        for i in range(len(p1_norm)):\n",
    "            p1_homogeneous = np.append(p1_norm[i], 1)\n",
    "            p2_homogeneous = np.append(p2_norm[i], 1)\n",
    "            error += np.abs(np.dot(p2_homogeneous, np.dot(E_mat, p1_homogeneous)))\n",
    "        return error\n",
    "\n",
    "    result = minimize(objective, E.flatten(), method='Nelder-Mead')\n",
    "    return result.x.reshape(3, 3)\n",
    "\n",
    "#### MOTION BUNDLE ADJUSTMENT ####\n",
    "def motion_only_bundle_adjustment(R, t, points_3d, points_2d, K):\n",
    "    def project(points_3d, rvec, tvec, K):\n",
    "        points_proj, _ = cv2.projectPoints(points_3d, rvec, tvec, K, None)\n",
    "        return points_proj.reshape(-1, 2)\n",
    "\n",
    "    def objective(params):\n",
    "        rvec, tvec = params[:3], params[3:]\n",
    "        points_proj = project(points_3d, rvec, tvec, K)\n",
    "        errors = points_proj - points_2d\n",
    "        return errors.ravel()\n",
    "\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    params = np.hstack((rvec.ravel(), t.ravel()))\n",
    "    \n",
    "    result = least_squares(objective, params, loss='soft_l1', f_scale=1.0, verbose=0)\n",
    "\n",
    "    R_opt, _ = cv2.Rodrigues(result.x[:3])\n",
    "    t_opt = result.x[3:].reshape(3, 1)\n",
    "\n",
    "    return R_opt, t_opt\n",
    "\n",
    "\n",
    "#### FEATURE DISTANCE MATCH TO SEE REPITION AND DECLARE A LOOP CLOSURE ####\n",
    "def detect_loop_closures(trajectory, descriptors, distance_threshold=5.0, similarity_threshold=0.7):\n",
    "    loop_closures = []\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "    nn.fit(trajectory)\n",
    "    \n",
    "    for i in range(len(trajectory)):\n",
    "        distances, indices = nn.kneighbors([trajectory[i]])\n",
    "        for j, distance in zip(indices[0], distances[0]):\n",
    "            if j > i + 10 and distance < distance_threshold:  # Avoid consecutive frames\n",
    "                matches = flann.knnMatch(descriptors[i], descriptors[j], k=2)\n",
    "                good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]\n",
    "                if len(good_matches) / len(matches) > similarity_threshold:\n",
    "                    loop_closures.append((i, j))\n",
    "    \n",
    "    return loop_closures\n",
    "\n",
    "### CERATES POSE GRAPH FOR OPTIMIZATION ####\n",
    "def create_pose_graph(trajectory, loop_closures):\n",
    "    g = nx.Graph()\n",
    "    for i in range(len(trajectory) - 1):\n",
    "        g.add_edge(i, i+1, weight=1)\n",
    "    \n",
    "    for i, j in loop_closures:\n",
    "        g.add_edge(i, j, weight=0.1)  # Lower weight for loop closures\n",
    "    \n",
    "    return g\n",
    "\n",
    "#### POSE GRAPH OPTIMIZATION ####\n",
    "def optimize_pose_graph(trajectory, pose_graph):\n",
    "    n = len(trajectory)\n",
    "    \n",
    "    def objective(x):\n",
    "        residuals = []\n",
    "        for u, v, data in pose_graph.edges(data=True):\n",
    "            p1 = x[u*3:u*3+3]\n",
    "            p2 = x[v*3:v*3+3]\n",
    "            weight = data['weight']\n",
    "            residuals.append((p2 - p1) * weight)\n",
    "        return np.concatenate(residuals)\n",
    "    \n",
    "    x0 = trajectory.flatten()\n",
    "    res = least_squares(objective, x0)\n",
    "    return res.x.reshape(-1, 3)\n",
    "\n",
    "\n",
    "#### CLAHE IMPLEMENTATION TO IMPROVE CONTRAST IN IMAGE FOR BETTER KEYPOINT IDENTIFICATION ####\n",
    "def enhance_contrast(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150716a-f575-4d6e-89c3-9d0d99fac171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kalman Filter initialization\n",
    "x_kalman = np.zeros(9)\n",
    "P_kalman = np.eye(9)\n",
    "Q_kalman = np.eye(9) * 1e-4\n",
    "R_kalman = np.eye(6) * 0.01  # 6x6 to include roll, pitch, yaw\n",
    "\n",
    "dt = 2.0  # Time step, can be set based on your frame rate\n",
    "F_kalman = np.eye(9)\n",
    "F_kalman[0, 3] = F_kalman[1, 4] = F_kalman[2, 5] = dt\n",
    "\n",
    "H_kalman = np.zeros((6, 9))\n",
    "H_kalman[0, 0] = H_kalman[1, 1] = H_kalman[2, 2] = 1\n",
    "H_kalman[3, 6] = H_kalman[4, 7] = H_kalman[5, 8] = 1\n",
    "\n",
    "# Main execution\n",
    "K = np.array([\n",
    "    [4085.11, 0, 3000],\n",
    "    [0, 4102.56, 2000],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "image_folder = input(\"Enter the path to the folder containing images: \")\n",
    "imu_file = input(\"Enter the path to the IMU data file: \")\n",
    "\n",
    "# Read IMU data\n",
    "imu_data = read_imu_data(imu_file)\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "images = []\n",
    "gray_images = []\n",
    "keypoints = []\n",
    "descriptors = []\n",
    "imu_matches = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    gray_img = enhance_contrast(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    images.append(img)\n",
    "    gray_images.append(gray_img)\n",
    "    \n",
    "    k, d = orb_detector_descriptor(gray_img)\n",
    "    keypoints.append(k)\n",
    "    descriptors.append(d)\n",
    "    \n",
    "    falling_edge, rising_edge = extract_timestamps_from_filename(image_file)\n",
    "    imu_data_for_image = find_closest_imu_data(imu_data, falling_edge, rising_edge)\n",
    "    \n",
    "    if imu_data_for_image is not None:\n",
    "        imu_matches.append(imu_data_for_image)\n",
    "    else:\n",
    "        imu_matches.append([np.nan]*4)  # Placeholder for no match\n",
    "\n",
    "# FLANN matcher\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "R_total = np.eye(3)\n",
    "t_total = np.zeros((3, 1))\n",
    "trajectory = [np.zeros(3)]  # Start at origin\n",
    "all_descriptors = [descriptors[0]]\n",
    "\n",
    "last_keyframe_kp = keypoints[0]\n",
    "last_keyframe_desc = descriptors[0]\n",
    "last_keyframe_index = 0\n",
    "\n",
    "R_total = np.eye(3)\n",
    "t_total = np.zeros((3, 1))\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    \n",
    "    if is_keyframe(keypoints[i], last_keyframe_kp):\n",
    "        matches = flann.knnMatch(last_keyframe_desc, descriptors[i], k=2) ## TRY CHANGING K=2 for more matches\n",
    "        good_matches = []\n",
    "        for match1, match2 in matches:\n",
    "            if match1.distance < 0.75 * match2.distance:\n",
    "                good_matches.append(match1)\n",
    "        \n",
    "        if len(good_matches) >= 8:\n",
    "            src_pts = np.float32([last_keyframe_kp[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([keypoints[i][m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            E, mask = cv2.findEssentialMat(src_pts, dst_pts, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "            E_refined = refine_E(E, src_pts, dst_pts, K)\n",
    "            \n",
    "            _, R, t, mask = cv2.recoverPose(E_refined, src_pts, dst_pts, K)\n",
    "            R_total = R @ R_total\n",
    "            t_total = t_total + (R_total @ t)\n",
    "            \n",
    "            last_keyframe_kp = keypoints[i]\n",
    "            last_keyframe_desc = descriptors[i]\n",
    "            last_keyframe_index = i\n",
    "\n",
    "            trajectory.append(t_total.flatten())\n",
    "            all_descriptors.append(descriptors[i])\n",
    "            \n",
    "            # Kalman Filter update\n",
    "            z = np.hstack([t_total.flatten(), imu_matches[i][1:4]])  # Position and IMU angles\n",
    "            x_kalman_pred = F_kalman @ x_kalman\n",
    "            P_kalman_pred = F_kalman @ P_kalman @ F_kalman.T + Q_kalman\n",
    "            y_kalman = z - H_kalman @ x_kalman_pred\n",
    "            S_kalman = H_kalman @ P_kalman_pred @ H_kalman.T + R_kalman\n",
    "            K_kalman = P_kalman_pred @ H_kalman.T @ np.linalg.inv(S_kalman)\n",
    "            x_kalman = x_kalman_pred + K_kalman @ y_kalman\n",
    "            P_kalman = (np.eye(len(x_kalman)) - K_kalman @ H_kalman) @ P_kalman_pred\n",
    "            \n",
    "            trajectory[-1] = x_kalman[:3]  # Update the trajectory with the filtered position\n",
    "\n",
    "# Detect loop closures\n",
    "trajectory_np = np.array(trajectory)\n",
    "loop_closures = detect_loop_closures(trajectory_np, all_descriptors)\n",
    "\n",
    "# Optimize the trajectory using pose graph optimization\n",
    "pose_graph = create_pose_graph(trajectory_np, loop_closures)\n",
    "optimized_trajectory = optimize_pose_graph(trajectory_np, pose_graph)\n",
    "\n",
    "# Plot the trajectory\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(trajectory_np[:, 0], trajectory_np[:, 2], label=\"Original Trajectory\")\n",
    "plt.plot(optimized_trajectory[:, 0], optimized_trajectory[:, 2], label=\"Optimized Trajectory\", linestyle='dashed')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Z\")\n",
    "plt.title(\"Trajectory\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a1201-67ed-4efe-a048-42d72704fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1],'ro-')\n",
    "plt.title('2D Trajectory')\n",
    "plt.show()\n",
    "\n",
    "nx.draw(pose_graph)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
